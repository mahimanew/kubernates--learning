
### **1. Exposing Custom Metrics in Python**

For **Python applications**, you can use the **Prometheus Python client library** to expose custom metrics.

#### **1.1 Install Prometheus Python Client**

To start, you need to install the **Prometheus client** for Python:

```bash
pip install prometheus_client
```

#### **1.2 Example Python Application with Custom Metrics**

Hereâ€™s an example of how to expose custom metrics in a Python application:

```python
from prometheus_client import start_http_server, Counter
import random
import time

# Define a custom counter metric
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP Requests', ['method', 'endpoint'])

def handle_request(method, endpoint):
    REQUEST_COUNT.labels(method=method, endpoint=endpoint).inc()
    print(f"Handled request: {method} {endpoint}")

if __name__ == '__main__':
    # Start Prometheus HTTP server to expose metrics
    start_http_server(8080)

    # Simulate handling requests and incrementing metrics
    while True:
        method = random.choice(['GET', 'POST'])
        endpoint = random.choice(['/home', '/about', '/contact'])
        handle_request(method, endpoint)
        time.sleep(1)
```

#### **1.3 Expose Metrics in Python**

This script:
- Starts an HTTP server on port `8080` to expose metrics at the `/metrics` endpoint.
- Simulates handling requests with random HTTP methods (`GET` or `POST`) and random endpoints (`/home`, `/about`, `/contact`).
- Exposes the total number of requests in a `Counter` metric, with labels `method` and `endpoint`.

Now, run the Python application:
```bash
python app.py
```
Prometheus can scrape metrics from `http://localhost:8080/metrics`.

---

### **2. Exposing Custom Metrics in Node.js**

For **Node.js applications**, you can use the **Prometheus Node.js client library** to expose custom metrics.

#### **2.1 Install Prometheus Node.js Client**

To start, install the **prom-client** library:

```bash
npm install prom-client
```

#### **2.2 Example Node.js Application with Custom Metrics**

Hereâ€™s an example of how to expose custom metrics in a Node.js application:

```javascript
const express = require('express');
const client = require('prom-client');
const app = express();
const port = 8080;

// Define custom counter metric
const httpRequestsTotal = new client.Counter({
  name: 'http_requests_total',
  help: 'Total HTTP requests',
  labelNames: ['method', 'endpoint'],
});

// Register the default registry for Prometheus
client.register.setDefaultLabels({
  app: 'my-node-app',
});

// Expose metrics at /metrics endpoint
app.get('/metrics', async (req, res) => {
  res.set('Content-Type', client.register.contentType);
  res.end(await client.register.metrics());
});

// Simulate handling requests and updating the counter
app.use((req, res, next) => {
  httpRequestsTotal.labels(req.method, req.originalUrl).inc();
  next();
});

app.get('/home', (req, res) => res.send('Home'));
app.get('/about', (req, res) => res.send('About'));
app.get('/contact', (req, res) => res.send('Contact'));

app.listen(port, () => {
  console.log(`Server listening at http://localhost:${port}`);
});
```

#### **2.3 Expose Metrics in Node.js**

In this script:
- It starts an HTTP server on port `8080` and exposes Prometheus metrics at `/metrics`.
- The custom `http_requests_total` counter is incremented for each incoming request with HTTP method and endpoint labels.

Now, run the Node.js application:
```bash
node app.js
```
Prometheus can scrape metrics from `http://localhost:8080/metrics`.

---

### **3. Scraping Custom Metrics with Prometheus**

Now that we have custom metrics exposed in both Python and Node.js, Prometheus needs to scrape them. As discussed before, configure Prometheus to scrape these metrics by adding the target in your `prometheus.yml` file.

For Python (replace `<python_app_pod_name>` with the pod name):
```yaml
scrape_configs:
  - job_name: 'python-app'
    static_configs:
      - targets: ['<python_app_pod_name>:8080']
```

For Node.js (replace `<node_app_pod_name>` with the pod name):
```yaml
scrape_configs:
  - job_name: 'node-app'
    static_configs:
      - targets: ['<node_app_pod_name>:8080']
```

---

### **4. Querying and Visualizing Metrics in Grafana**

#### **4.1 Querying Custom Metrics**

In **Grafana**, you can query the custom metrics exposed by both applications using **PromQL**. For example, to visualize the number of HTTP requests, use the query:

```prometheus
http_requests_total
```

#### **4.2 Creating Dashboards**

1. **Grafana Panel**: Create a new panel and use the above query to create a visualization for the custom metric.
2. **Customize**: You can create a **graph**, **table**, or **bar chart** to represent the data. You can filter it based on labels like `method` or `endpoint`.

#### **4.3 Alerting on Custom Metrics**

You can set up **alerts** in Grafana based on custom metrics. For instance:
- Create an alert if the total HTTP request count exceeds a threshold, or if the response time is too high.

---

### **5. Integrating Custom Metrics with Horizontal Pod Autoscaler (HPA)**

As discussed earlier, **custom metrics** can also be used for **Horizontal Pod Autoscaling**. To autoscale based on HTTP requests, use the same `http_requests_total` metric in the HPA definition:

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: custom-metrics-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: External
    external:
      metric:
        name: http_requests_total
        selector:
          matchLabels:
            method: "GET"
            endpoint: "/home"
      target:
        type: Value
        value: "100"
```

This configuration will scale the application based on the number of **GET requests to the `/home` endpoint**.

---

### **ðŸ“Œ Summary of Python and Node.js Metrics**

- **Python** and **Node.js** both support Prometheus client libraries that help expose **custom metrics**.
- You can use these metrics in **Prometheus** for scraping and storing.
- In **Grafana**, you can visualize these metrics to gain insights into application performance.
- Integrating custom metrics into **Horizontal Pod Autoscaler** helps automatically scale your application based on load.

---

