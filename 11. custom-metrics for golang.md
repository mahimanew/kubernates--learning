
### **ðŸ“Œ Exporting Custom Metrics to Prometheus**

To collect and visualize **custom application metrics**, you can use **Prometheus client libraries**. These libraries are available in multiple programming languages (Go, Python, Java, Node.js, etc.), and they help expose metrics in a format that Prometheus can scrape.

---

### **Step 1: Expose Custom Metrics in Your Application**

Letâ€™s assume you have a **Go application** running inside a pod in Kubernetes. You can expose metrics from your application using the Prometheus Go client.

#### **1.1 Install Prometheus Go Client**
You need to install the **Prometheus Go client library** in your application. You can do this by running:

```bash
go get github.com/prometheus/client_golang/prometheus
```

#### **1.2 Example Go Application with Custom Metrics**

Hereâ€™s a simple example of how to expose custom metrics in your Go application:

```go
package main

import (
	"fmt"
	"log"
	"net/http"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
	// Define a custom counter metric
	httpRequests = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "http_requests_total",
			Help: "Total number of HTTP requests",
		},
		[]string{"method", "endpoint"},
	)
)

func init() {
	// Register the custom metric with Prometheus
	prometheus.MustRegister(httpRequests)
}

func handler(w http.ResponseWriter, r *http.Request) {
	// Increment the counter metric
	httpRequests.WithLabelValues(r.Method, r.URL.Path).Inc()
	fmt.Fprintf(w, "Hello, World!")
}

func main() {
	// Handle HTTP requests and serve the metrics
	http.HandleFunc("/", handler)
	http.Handle("/metrics", promhttp.Handler()) // Expose the metrics at /metrics
	log.Fatal(http.ListenAndServe(":8080", nil))
}
```

#### **1.3 Expose Metrics**
In the above example, the application exposes the metrics at the `/metrics` endpoint. This endpoint is where **Prometheus** scrapes the data. 

- Start the Go application: `go run main.go`.
- Now the application is available at `http://localhost:8080/metrics`.

---

### **Step 2: Scrape Custom Metrics in Prometheus**

Prometheus needs to be configured to scrape the `/metrics` endpoint from your application to collect the custom metrics.

#### **2.1 Add the Target to Prometheus**

In your **Prometheus configuration file** (`prometheus.yml`), you need to add a scrape configuration for your custom application:

```yaml
scrape_configs:
  - job_name: 'my-app'
    static_configs:
      - targets: ['<application_pod_name>:8080']
```

This tells Prometheus to scrape the `/metrics` endpoint on your applicationâ€™s pod every 15 seconds by default.

---

### **Step 3: Create Dashboards in Grafana for Custom Metrics**

Once Prometheus is scraping the custom metrics, you can visualize them in **Grafana**.

#### **3.1 Querying Custom Metrics in Grafana**
In Grafana, you can use **PromQL** to query the metrics youâ€™ve exposed. For instance, to visualize the total number of HTTP requests for each endpoint and HTTP method:

```prometheus
http_requests_total
```

#### **3.2 Create a Grafana Panel**
1. Go to **Grafana** and create a new dashboard.
2. Add a **panel** and use the above **PromQL** query in the **Metrics** field.
3. You can customize the visualization, such as showing the data in a **graph**, **table**, or **bar gauge**.

---

### **Step 4: Integrating Custom Metrics with Horizontal Pod Autoscaler (HPA)**

You can also use your custom metrics to **autoscale** your pods in Kubernetes using **Horizontal Pod Autoscaler (HPA)**.

#### **4.1 Enable Custom Metrics in Kubernetes**

Ensure that the **metrics-server** is installed and configured to collect metrics.

1. **Install the metrics-server** if it's not already installed:
   ```bash
   kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
   ```

2. Verify the metrics-server is working by checking its API:
   ```bash
   kubectl get apiservices v1beta1.metrics.k8s.io
   ```

#### **4.2 Define the HPA Resource**

To autoscale based on your custom metrics, youâ€™ll need to define an **HPA** resource. Hereâ€™s an example of an HPA that scales pods based on HTTP request count:

```yaml
apiVersion: autoscaling/v2beta2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
  namespace: default
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 1
  maxReplicas: 10
  metrics:
  - type: External
    external:
      metric:
        name: http_requests_total
        selector:
          matchLabels:
            method: "GET"
            endpoint: "/"
      target:
        type: Value
        value: "100"
```

This HPA will scale the `my-app` deployment based on the total number of HTTP requests to the `/` endpoint (GET requests). When the number of requests exceeds **100**, Kubernetes will increase the number of pods.

---

### **Step 5: Best Practices for Custom Metrics**

Here are some best practices to consider when dealing with **custom metrics** in Kubernetes:

1. **Use Namespaces and Labels**: Always use **labels** to differentiate between various application environments (e.g., production, staging). This helps when you have multiple applications sharing the same Prometheus instance.

2. **Metrics Granularity**: Donâ€™t expose too many granular metrics. Focus on the most critical business-related metrics that provide insights into your applicationâ€™s health and performance.

3. **Optimize Metric Collection**: Keep the metric collection frequency in mind. Scraping too frequently can overwhelm your Prometheus instance and increase resource usage.

4. **Alerting on Custom Metrics**: Use **Prometheus Alertmanager** to create alerts based on custom metrics. For example, if the number of HTTP requests exceeds a threshold, or if response times are too high, you can be alerted.

---

### **ðŸ“Œ Summary**

By exposing custom application metrics using Prometheus client libraries and scraping them with Prometheus, you can monitor application-specific behaviors that go beyond Kubernetes metrics. Integrating these metrics into **Grafana** enables powerful visualizations, and using **Horizontal Pod Autoscaler (HPA)** helps to scale your application based on real-time load.

